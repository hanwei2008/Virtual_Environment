#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Author: caiyuantao
# @Date:   2014-12-18
# @Email: 755864446@qq.com
# svmpredict.py
#
# Copyright (c) 2014 Chengdu Lanjing Data&Information Co., Ltd
import os
import sys
from pyspark import SparkContext
import cPickle as pickle
from numpy import array
from util import read_file
from preprocess import *


def svm_predict(content):
    if type(content) != unicode:
        raise TypeError("需要传入的参数必须为unicode")

    curpath = os.path.normpath(os.path.join(os.getcwd(), os.path.dirname(__file__)))
    stopwords = set(read_file(os.path.join(curpath, u"stopwords.txt")).split())

    # 分词, 去停用词, 词频统计
    file_counter = word_counter(word_filter(word_segment(content), stopwords))

    # 在分类器下的结果
    result = []
    for file_name in os.listdir(curpath):
        if file_name.endswith('.pkl'):
            with open(os.path.join(curpath, file_name), 'rb') as pkl_file:
                features, idf, classifier = pickle.load(pkl_file)
                tf = [file_counter[key] for key in features]
                vector = [i_tf * i_idf for i_tf, i_idf in zip(tf, idf)]
                value = classifier.predict(array(vector))
                value[0] = file_name.split('.')[0].split('_')[1] if value[0] == '1' else file_name.split('.')[0].split('_')[2]
                #   有待正则表达式的改进，是对应svm_train.py得到的pickl命名规则svm_xxxx_yyy.pkl只需要xxxx 和 yyy
                result += value

    if len(result) == 0:
        raise OSError('没有训练好的pickle文件')

    # 如果分类结果多余一个，说明是多个二元分类器，则需要判断最终属于哪一类
    if len(result) > 2:
        category = result[0:len(result):2]
        margin = result[1:len(result):2]
        if len(category)==len(set(category)):
            temp = 0
            for i, j in enumerate(margin):
                if j > temp:
                    temp = j
                    index = i
            return index
        else:
            return collections.Counter(category).most_common(1)[0][0]

    else:
        return result[0]


if __name__ == "__main__":

    if len(sys.argv) < 2:
        print >> sys.stderr, "Usage: svmpredict <file_name>"
        exit(1)

    sc = SparkContext("local", "svmpredict.py")
    svm_predict(sys.argv[1])
    sc.stop()
